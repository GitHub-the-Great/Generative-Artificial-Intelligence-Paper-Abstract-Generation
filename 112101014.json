{"paper_id": 408, "abstract": "In the realm of generative adversarial networks (GANs), the quest for optimal configurations often leads us to find ourselves in the murky waters of disconnected data distributions, where we find ourselves at the mercy of Gaussian isoperimetric inequalities.  In this paper, we embark on a quest to illuminate the intricate relationship between these inequalities and the latent space of GANs. Our exploration reveals a fascinating truth: as long as the number of components in a partition and the dimensionality of the Gaussian space are aligned, the optimal partition emerges as a 'simplicial cluster,' a Voronoi diagram derived from the cells of equidistant points.   To illuminate the implications of this insight, we introduce the precision metric, a tool that quantifies the portion of generated data that falls outside the bounds of the true data distribution. Through this metric, we uncover two pivotal insights: first, that when a GAN is organized as a simplicial cluster, it achieves an upper bound on its precision. Second, we demonstrate that this approach not only enhances GAN performance but also enhances the precision of its latent space."}
{"paper_id": 409, "abstract": "In the realm of machine learning, the quest for counterfactual representation emerges as a formidable challenge, one that demands the ability to predict the outcome of an intervention on an outcome of interest to guide decision-making. Traditionally, the challenge has been to harness the power of loss functions to predict both observed outcomes and those that await them in the real world. Yet, despite the many promising approaches that have emerged in this field, a critical gap remains: the absence of a consistent loss function that can be harnessed to train expressive representations.  In this paper, we unveil a novel approach: the dual-robust estimator, a groundbreaking tool designed to ensure convergence and consistency in treatment effect estimation across a diverse array of treatment types and dosage parameters. Our findings reveal that this doubly robust estimator not only meets but surpasses the theoretical guarantees that have long defined the current state-of-the-art in this realm.  Yet, we do not stop there; we delve into the intricacies of the heuristic neural network architecture, where we propose a novel heuristic for the estimation of treatment effects. This innovative approach not only empowers the estimator to navigate the complexities of multiple treatment types but also empowers it to anticipate the outcomes that lie"}
{"paper_id": 410, "abstract": "In the ever-evolving realm of machine learning, the art of deep learning has emerged as a beacon of innovation, propelled by the power of increasingly powerful computer hardware. Yet, as we embark on this journey, we find ourselves at a crossroads, confronted by the specter of increasing hardware and energy demands.   In this exploration, we delve into the intricacies of these issues, dissecting their intricacies through the lens of socioeconimic, scientific, and environmental concerns.  Our findings reveal a profound correlation between the development of deep neural networks and the rise of general-purpose computing on graphics processing units (GPGPUs). Yet, we do not stop there; we delve deeper, delving into the implications of these concerns within the realm of applied machine learning.  In our findings, we examine the applicability of our findings within the fields of biology and chemistry."}
{"paper_id": 411, "abstract": "In the ever-evolving realm of deep learning, the quest for efficient regularization methods has emerged as a formidable challenge. Recent studies have illuminated the potential of gradient regularization (GR), a method that harnesses the power of the gradient norm to enhance generalization performance. However, the theoretical underpinning of GR remains shrouded in mystery, particularly when it comes to the intricate dance of gradient ascent and descent.  In this work, we embark on a journey to unravel the complexities of finite-difference GR, revealing that it not only achieves a remarkable level of efficiency but also possesses a profound advantage in generalization.  Our exploration reveals that GR not only excels in generalizing but also exhibits an implicit bias toward solutions in the rich regime, a trait that could lead to greater generalization efficiency.  To further illuminate our findings, we present a theoretical analysis of the performance improvement achieved by GR in a theoretically solvable diagonal linear network (DLN). Our findings reveal that the GR method not only enhances generalization but also enhances the selection of global minima within the DLN. This insight not only aligns with the principles of sharpness-aware minimization (SAM) and the flooding method (Ishida et al., 2020) but also align"}
{"paper_id": 412, "abstract": "In the ever-evolving realm of machine learning, the quest for deep-learning representations often leads us down the path of t-SNE (t-distributed stochastic neighbor embedding) plots, where we seek to unravel the intricate tapestry of data through the lens of image embeddings. Yet, these plots remain shrouded in mystery, often shrouded in secrecy, even as we embark on a quest to unravel their secrets.  In this paper, we unveil a novel approach: the property inference attack. This innovative approach harnesses the power of an image classifier to distinguish between distinct representations from the target model. Our evaluations reveal that this attack not only achieves high accuracy but also stands shoulder to shoulder with the best models across a diverse array of datasets, including CelebA, LFW, and FairFace. However, we do not stop there. We uncover that the vulnerability of our attack can be mitigated through the clever application of Gaussian noise.  To mitigate this vulnerability, we introduce an adaptive defense, crafted to amplify the impact of the attack. Our findings reveal that the shadow model employed by the attack is not merely a mere extension of the target, but a potent ally, capable of enhancing its performance to match the performance of"}
{"paper_id": 413, "abstract": "In the ever-evolving realm of data security, the realm of backdoor attacks has emerged as a formidable adversary, one that threatens the very fabric of our knowledge. In this work, we unveil a groundbreaking approach: the poison-label backdoor attack, a method that harnesses the power of a predefined trigger pattern to inject maliciously into the training data of benign samples. This innovative approach not only enhances the efficiency of the attack, but it also ensures that the trigger pattern is not inadvertently activated during the attack.  At the heart of our approach lies the extraction of this trigger pattern from benign data, a phenomenon that occurs infrequently in samples belonging to the target class but rarely occurs in samples of non-target classes.  To navigate this delicate balance, we introduce a framework that allows us to extract the trigger patterns from benign samples, deftly injecting them into the attack's training data.  Our experiments reveal that this method not only meets the challenges of low-effort detection and mitigation but also enhances the resilience of the model against the effects of the backdoors."}
{"paper_id": 414, "abstract": "In the ever-evolving realm of deep learning, the quest for accuracy and efficiency stands as a formidable challenge. Enter network binarization, a powerful compression technique that seeks to reduce the bit-width to a mere 1-bit. Yet, a troubling trend has emerged in the landscape of academic research: the focus on accuracy is often confined to monotonic tasks, often neglecting the intricate intricacies of real-world edge hardware.   In this paper, we unveil a groundbreaking benchmark, Bibench, designed to assess the efficiency and accuracy of binarized network algorithms across a diverse array of diverse tasks.  At the heart of our approach lies a comprehensive evaluation of accuracy and training efficiency across seven distinct evaluation tracks: \"Learning Task,\" \"Neural Architecture,\" \"Corruption Robustness,\" \"Training Consumption,\" \"Theoretical Complexity,\" and \"Hardware Inference.\"  Through this rigorous evaluation framework, we forge a path forward, illuminating the path for future advancements in the field.  Our findings reveal that the current state-of-the-art binarizations, while heralded for their theoretical prowess, falter in the practical realm, particularly when it comes to the performance of large-scale training tasks like CIFAR"}
{"paper_id": 415, "abstract": "In the ever-evolving landscape of machine learning, the specter of Out-Of-Distribution (OOD) has emerged as a formidable foe, threatening the very fabric of our understanding. Recent advancements in multivariate detection techniques have sought to harness the power of OOD scores to illuminate the path of input samples through the layers of a multi-layer classifier. Yet, these methods often overlook the sequential nature of these scores, neglecting the intricate interplay between each layer and the input.  In this paper, we unveil a novel approach that reimagines the OOD detection challenge from a functional perspective, reimagining it as a journey through the intricate tapestry of neural networks.    Our approach not only captures the statistical intricacies of input trajectories but also empowers us to measure the similarity of these trajectories with the training data, revealing that the input sample is likely to be from an OOD dataset.  To validate our approach, we rigorously benchmarked it against a mid-size OOD benchmark, uncovering an average ROC gain of 3.7% across various classifier architectures.  The results speak for themselves: our method not only identifies OOD samples without the need for additional OOD or synthetic"}
{"paper_id": 416, "abstract": "In the ever-evolving realm of super-resolution, the quest to reconstruct a high-resolution image from its low-resolution counterpart has emerged as a formidable challenge. Traditionally, this task has been approached through the lens of supervised deep learning, where the intricate tapestry of synthetic datasets serves as a guiding light. Yet, this approach often overlooks the intricate dance of degradations that lie beneath.  In this paper, we embark on a journey to unravel the intricate interplay between these synthetic datasets and their unpaired counterparts. Specifically, we delve into the Optimal Transport (OT) objectives of Generative Adversarial Networks (GANs) from a theoretical perspective.  Our exploration reveals that these GAN optimization objectives, when regularized with content losses, are inherently biased toward optimal transport maps.  To counter this bias, we introduce a novel algorithm designed to harness the power of integral probability metrics (IPMs) to illuminate the intricate connections between our algorithm and regularized GANs.  At the heart of our findings lies a minimax minimax optimization objective, which not only aligns with the optimal transport objective but also serves as the foundation of our algorithm's performance in the unpaired image SR challenge.  Through rigorous experimentation"}
{"paper_id": 417, "abstract": "In the ever-evolving realm of 3D scene perception, point clouds stand as a beacon of hope, providing a rich tapestry of geometric information. Yet, as we delve deeper into the intricate landscape of real-world scenarios, we find ourselves confronted with a formidable challenge: the challenge of domain generalization under the constraints of zero-shot target domains.  In this paper, we embark on a quest to unravel the complexities of this challenge, unveiling a groundbreaking framework known as Singe-dataset Unified Generalization (SUG). At the heart of SUG lies a Multi-grained Sub-domain Alignment (MSA) method, designed to address the challenges posed by the unknown domain-variance challenge. To tackle these challenges head-on, we introduce a novel approach: the Multi-Domain Adaptation (MDA) framework. This innovative approach is designed to adapt the model to the varied data distributions of multiple target domains, ensuring that it can seamlessly adapt to the needs of any given target domain. Through rigorous experimentation, we demonstrate that our SDA method not only adapts to the diverse data distributions within a single target domain but also excels in its cross-domain generalization capabilities.    To further illuminate our"}
{"paper_id": 418, "abstract": "In the ever-evolving realm of deep neural networks, we find ourselves at a pivotal moment: the dawn of distribution shift detection. Traditionally, we have approached this challenge through the lens of statistical black-box shift detection (BDSD), a method that relies heavily on two-sample statistical tests. Yet, we propose a novel approach: the use of selective prediction, where we quantify the uncertainty inherent in a classifier\u2019s prediction uncertainty and abstain from predicting uncertain instances. This approach is not merely theoretical; it can be applied to the intricate tapestry of real-world applications, such as in the realm of machine learning.  In this paper, we embark on a quest to uncover the distributional shifts that have plagued our favorite deep neural models. Our exploration reveals a fascinating truth: when the underlying distribution remains the same, a violation in this distribution shift can signal a shift in the distribution of the classifier itself. To illuminate this phenomenon, we introduce a rigorous empirical coverage-based detection framework, designed to ensure that our method does not violate the bounds set by BDSD.  Our results speak for themselves: our method not only surpasses ImageNet but also outshines it in terms of performance.    In"}
{"paper_id": 419, "abstract": "In the ever-evolving realm of 3D scene and layout generation, we unveil a groundbreaking approach to attribute-level conditioning. Traditional autoregressive models, while adept at generating a sequence of tokens, often impose a strict sequential order that constrains the generation of objects. This limitation, coupled with the limitations of the generative nature of these models, can lead to a frustrating stalemate when it comes to the selection of attributes to be conditioned on.  Enter ATISS, a groundbreaking model designed to harness the power of randomly permuting furniture objects during training, paving the way for the art of attribute conditioning.    At the heart of ATISS lies a novel encoder-decoder architecture, designed to provide bidirectional attention through an encoder, allowing the model to look ahead, ensuring that all values in the sequence can be given as a condition.  In our experiments, we demonstrate that ATISS not only meets the challenge but also surpasses the performance of its predecessor.  To ensure that our model does not falter, we introduce a cross-level attribute detection mechanism, allowing us to discern the most likely class, orientation, and size of objects at a given location. This ensures that we do not suffer the same fate as"}
{"paper_id": 420, "abstract": "In the ever-evolving realm of neural networks, the art of transfer learning has emerged as a beacon of hope. This innovative approach seeks to transfer the knowledge of a trained model from the source domain to the target domain, where only a limited amount of data exists. Yet, as with any endeavor, the journey is fraught with challenges. Traditionally, the focus has been on the accuracy of the model, but we find that the true test of its robustness lies in its ability to withstand the vagaries of distribution shifts.  In this paper, we embark on a quest to unravel the intricate tapestry of source and target retraining. We delve into the intricacies of each training procedure, uncovering a fascinating correlation between the robustness of a model and its transferability.  At the heart of our exploration lies the H-score\u2014a measure that quantifies the transferability of model representations within a given domain.  To further illuminate our findings, we introduce robustness certification, a rigorous metric that assesses the model's robustness under a variety of performance distribution shifts, such as random noise, contrast, and Gaussian shift.  Our findings reveal a compelling correlation between model robustness and transferability, particularly when it comes to transferability"}
{"paper_id": 421, "abstract": "In the realm of deep reinforcement learning (DRL), we unveil a groundbreaking approach: scenario-based programming (SBP). This innovative approach harnesses the power of scenarios to forge safe and reliable policies for the intricate realm of safety-critical tasks. At the heart of SBP lies a novel approach to encoding constraints into the DRL training process, allowing users to craft their own guidelines.  Through rigorous experimentation, we demonstrate that SBP not only enhances the performance of DRL-based policies but also enhances their robustness and predictability.   To substantiate our findings, we conducted a rigorous analysis of the behavior of our SBP-trained policies, conducted on the Robotis Turtlebot3 platform. This analysis revealed that our approach not only meets but surpasses existing state-of-the-art DRL policies for a variety of safety critical tasks, such as navigation and manipulation.  The results of our experiments speak volumes: SBP generates policies that adhere to these user-defined constraints without compromising performance."}
{"paper_id": 422, "abstract": "In the ever-evolving realm of Deep Reinforcement Learning (DRL), we unveil a novel defense strategy: the Knowledge-based Policy Fusion (KPR). This innovative approach harnesses the power of knowledge encoded in auxiliary task policies to fortify against adversarial attacks.   At the heart of our approach lies the knowledge encoded within these policies, which serves as the foundation for an ensemble of policies.  At its core, the KPR harnesses existing task policies as structural priors, harnessing the rich tapestry of knowledge embedded in these policies. This knowledge serves as a guide for the transfer of knowledge and generalization of high-level specifications.  Our findings reveal that while a single task policy can be targeted, perturbing multiple policies at the same time can be a formidable foe.  In this way, we forge a bridge between the strengths of our policies and the resilience of our knowledge-based framework, enabling us to navigate the treacherous waters of adversarial training and detection.  Through rigorous empirical testing, we demonstrate that our KPR framework not only withstands but thrives against the onslaught of adversary attacks but also thrives in its resilience."}
{"paper_id": 423, "abstract": "In the ever-evolving realm of machine learning, the CLIP pre-trained model has emerged as a beacon of promise. Yet, despite its prowess in the realm of image-text retrieval, its ability to match images that stray from its training data distribution remains shrouded in mystery.  In this paper, we embark on a quest to unravel this mystery through the lens of continuous training, a groundbreaking approach that harnesses the power of streaming data. We introduce a novel framework we call Mod-X, which deftly aligns the off-diagonal information distribution of the contrastive matrix with the current state of the current model, while maintaining the accuracy of the old model. Our experiments reveal that this approach not only enhances the performance of the model but also enhances its cognitive resilience. The results speak for themselves."}
{"paper_id": 424, "abstract": "In the realm of Model-Based Reinforcement Learning (MBRL), the art of learning unfolds through the lens of an experience replay buffer. This buffer serves as a repository for the agent's observations, its actions in response to observations, the resulting reward, and new observations. This information is used to craft a single-shot dynamics model, a tool that predicts the outcomes of imagined actions into a trajectory of future states. Yet, as we delve into the intricate tapestry of MBRL, we find ourselves at a crossroads: the size of the replay buffer and the maintenance strategy of the model pose formidable challenges. Too large a replay buffer can lead to overfitting, while too small one can stifle the capacity for learning.  In this paper, we embark on a quest to curate the buffer based on the predictability of our model, ensuring that it captures both common and sporadic experiences with sufficient detail for prediction in longer learning sessions.   Our approach is rooted in three distinct strategies: determining reliable predictions of the dynamics model with respect to the imagined actions, retaining only the unimaginable experiences, and training further only when sufficient new experiences have been gleaned. These strategies pave the way for a model to self-manage both its buffer size and its"}
{"paper_id": 425, "abstract": "In the ever-evolving realm of artificial intelligence, the quest for deep neural networks (DNNs) stands as a beacon of hope, illuminating the path forward in the realm of machine learning. In this paper, we embark on a journey to unravel the mysteries of DNNs, uncovering the secrets behind their remarkable prowess.  Our journey begins with a journey through the intricate landscape of neural networks, revealing their roots in the very foundations of human reasoning. We delve into the intricacies of deep learning, revealing a fascinating tapestry of neural connections that weave together the threads of human thought and understanding. Our journey leads us to the fascinating realm of deep neural"}
{"paper_id": 426, "abstract": "In the ever-evolving realm of reinforcement learning, we unveil a groundbreaking approach: the Auto-Encoding Adversarial Imitation Learning (AEAIL). This innovative framework reimagines the reward function as an auto-encoder, crafting it as a reconstruction error. Our approach not only captures the full spectrum of state-action pairs but also captures the subtle differences between expert samples and agent-generated samples.  Through rigorous experimentation across a diverse array of environments, we demonstrate that our AEAIL stands shoulder to shoulder with state-of-the-art methods across a spectrum of tasks.  The results speak for themselves: our method not only achieves superior performance on a variety of tasks but also demonstrates a remarkable ability to adapt to the nuances of distribution divergences."}
{"paper_id": 427, "abstract": "In the ever-evolving realm of video-capture devices, a new trend has emerged: photorealistic video style transfer, or automatic color stylization. This technique seeks to replace color styles in original videos with one or multiple reference images, all while maintaining the spirit of \"photorealism\" in the process. Yet, the path to real-time style transfer is fraught with challenges, particularly when it comes to the creation of spatial distortions and the need to run in realtime. In this paper, we unveil a groundbreaking framework designed to tackle these challenges head-on.  At the heart of our approach lies a novel style removal and restoration framework, designed to remove the original content without destroying image structures. This innovative framework serves as both a stylization target and a source of inspiration for the stylization process.  To complement our style removal framework, we introduce decoupled instance normalization, a method that seamlessly harmonizes the styles of content images with those of reference images.  Our findings reveal that this method not only enhances the performance of style transfer but also enhances the overall quality of video content. The results of our experiments can be seen in a variety of real-world applications, ranging from video tutorials to gaming."}
{"paper_id": 428, "abstract": "In the ever-evolving realm of natural language processing, the art of relative positional encoding has emerged as a beacon of promise, illuminating the path for transformers. Traditionally, the focus has been on absolute positional encoding, a method that crafts a continuous representation for each position in a sequence. Yet, recent advancements have illuminated the path to relative positional encodings for linear transformers, a revelation that has sparked a flurry of interest in the field.  In this work, we unveil a groundbreaking approach: linearized relative positional encode, or LRPE. LRPE stands as a special form of LRPE, crafted specifically for the purpose of encoding relative positional matrices.  Our exploration reveals that LRPE not only achieves a decomposable encoding, but it also boasts a remarkable unitary property. By harnessing the power of unitary transformation, LRPE can effectively derive the linear space-time complexity of the linearized positional matrix.  To further illuminate LRPE\u2019s potential, we introduce a set of non-exhaustive linearized LRPE solutions, each tailored for a specific subset of RLPE. These solutions are not merely extensions; they stand as stand-ins for the LRPE family, providing a robust foundation for future RLPE"}
{"paper_id": 429, "abstract": "In the ever-evolving realm of multi-agent decision-making (MARL), the quest for optimal policy decisions is akin to finding an optimal return. This quest involves the delicate balance between exploration and exploitation across multiple agents, a challenge that has remained largely uncharted in the realm of RL.  In this paper, we unveil a novel framework that harnesses the power of entropy regularization for adaptive exploration in MARL. Our approach is grounded in the principles of disentanglement, a technique that dissects the joint soft value function into two distinct types: one for the return and the other for the entropy sum.  Through this method, we propose a metric for the desired level of exploration for each agent, based on the partial derivative of the joint value function of pure return with respect to (w.r.t.) policy action entropy.   At the heart of our framework lies the concept of value factorization\u2014a clever approach that allows us to separate the contributions of return and entropy from those of action entropy, allowing us to tailor our metric to the individual agent's needs.  The results of our experiments reveal that our framework not only meets but surpasses existing state-of-the-art exploration algorithms across a diverse array of agents"}
{"paper_id": 430, "abstract": "In the ever-evolving realm of reinforcement learning, we unveil a groundbreaking algorithm designed specifically for robust Markov Decision Processes (MDPs). This innovative framework, inspired by the robust bellman equation, seeks to harness the power of stochastic optimization to forge robust MDPs with a rectangular uncertainty set. Yet, as we delve deeper, we discover that this optimization approach is not without its limitations, particularly when faced with the intricate landscape of the MDP itself. This is not only a challenge of sample complexity; it also presents a formidable challenge of maximizing the number of episodes within the uncertainty set, a task that demands an efficient algorithm.   In this paper, we embark on a quest to forge a robust policy optimization algorithm that not only meets the challenge but also surpasses it.  Our results reveal that our algorithm not only achieves a sublinear regret but also achieves it with remarkable efficiency.  To further validate our findings, we conduct a series of rigorous experiments across a diverse array of MDP environments, including a robust online MDP and a robust offline MDP.  The results of our experiments speak for themselves, revealing that our method not only attains sub-linear regret in both the rectangular and s-angular uncertainty sets but also"}
{"paper_id": 431, "abstract": "In the ever-evolving realm of deep neural networks, where the quest for convergence and generalization reigns supreme, the singular adaptive gradient method (AGD) has emerged as a beacon of hope. Yet, as we embark on a quest to harness its potential, we find ourselves confronted with two formidable challenges: first, the challenge of balancing the loss from several descent directions, and second, the daunting task of optimizing for the entire space.   In this paper, we unveil a novel approach known as the Dimension-Reduced Adaptive Gradient Method (DRAG). This innovative method seeks to bridge the gap between the convergence speed of AGD and the generalization prowess of SGD. At the heart of our approach lies a trust-region-like approach, designed to streamline the learning rate and minimize the loss along a single gradient direction. Through rigorous theoretical rigorization, we demonstrate that on non-convex stochastic gradient problems, DRAG not only meets but surpasses the performance of its predecessors but also surpasses state-of-the-art performance on test sets.  To further illuminate our findings, we introduce a low-dimensional trust-regions subproblem, where we employ a quadratic approximation to estimate the"}
{"paper_id": 432, "abstract": "In the ever-evolving realm of machine learning, the quest for anomaly detection has emerged as a formidable challenge, one fraught with the specter of data paucity. This challenge is particularly acute in the realm of industrial systems, where anomalies can signal a departure from the norm.  In this paper, we unveil a groundbreaking approach: Long Short-term Memory Networks (LSTMs), designed to tackle this challenge head-on. We introduce a novel approach: quantile-based LSTMs, a groundbreaking technique that harnesses the power of quantiles to illuminate the path to anomaly detection.  Our approach is not merely theoretical; it is grounded in the principles of non-parametric non-linear dynamical systems, such as the Parameterized Elliot (PEF) activation function.    Through rigorous experimentation across a diverse array of industrial and non-industrial datasets, we demonstrate that the LSTM with PEF not only excels in anomaly detection but also outshines the state-of-the-art in terms of performance across a multitude of benchmark datasets, including the VLDB anomaly benchmark and the Numenta Anomaly Benchmark.  To navigate the complexities of anomaly detection, we introduce a groundbreaking template,"}
{"paper_id": 433, "abstract": "In the ever-evolving realm of graph contrastive learning (GCL), the quest for rationale discovery stands as a beacon of hope, illuminating the path to high-quality representations. Yet, as we delve deeper into the intricate tapestry of graph augmentation, we encounter two formidable challenges: the first is the lack of view diversity, and the second is the inherent limitations of the generator-encoder scheme.   To navigate these complexities, we introduce a novel approach: the \"self-encoding\" generator. This innovative framework harnesses the power of self-attention to forge pairwise pairwise connections between nodes and edges, enabling us to forge high- quality representations without the burden of hand-annotated labels.  At the heart of our approach lies a novel self-encoded selfattention token, which serves as both a proxy proxy for node and edge importance and a guide to the creation of rationales. This token serves as a powerful tool, deftly guiding the generator through the intricate dance of node-and edge-wise transformations.  Through this innovative approach, we forge a path forward, paving the way for a new era in contrastive optimization. Our approach not only enhances the performance of GCL models but also enhances"}
{"paper_id": 434, "abstract": "In the ever-evolving realm of neuroimaging, the art of decoding has emerged as a beacon of hope, illuminating the path forward in the quest for understanding the intricate dance of brain activity. Traditionally, the intricate tapestry of subject-level and group-level decoding models has proven to be a formidable ally, but we propose a bold new approach: the concept of across-subject decoding. In this endeavor, we embark on a quest to harness the power of data from multiple subjects, harnessing the wisdom gleaned from them all to forge a model that can generalize across all subjects. To achieve this, we introduce a novel approach known as group decoding, a method that empowers us to train a single group decoding model tailored to each subject. This method not only enhances the performance of group decoding models but also enhances their ability to predict the accuracy of left-out trials.   To illuminate our approach, we present two distinct approaches to evaluating decoding models: within-subject (SL) evaluation and GL evaluation. In SL evaluation, we delve into the intricacies of subject embeddings, examining the efficacy of various GL models across a diverse array of subjects. In GL analysis, we tackle the challenges posed by the vast array of left"}
{"paper_id": 435, "abstract": "In the realm of active learning, the quest for generalization often feels like a daunting challenge, fraught with the specter of overfitting and the loss of the training dataset.  In this paper, we unveil a novel approach: Sharpness-Aware Active Learning (SAAL). This innovative method harnesses the power of loss sharpness to craft the acquisition function. At the heart of SAAL lies the first eigenvalue of loss Hessian, which is intricately tied to the generalization ability of the model.  Our theoretical exploration reveals that SAAL not only meets this threshold but also surpasses the baselines in a variety of vision-based tasks.    In a further twist, we introduce a pseudo-labeling scheme that deftly distills the perturbed loss into a single value, allowing us to calculate the acquisition score for SAAL without the need to observe the labels of the unlabeled instances. In this way, SAAL navigates the treacherous waters of pseudo-labels, where we must contend with the limitations of pseudo labels and the constraints of real-world data.  To further illuminate our findings, we delve into the implications of our pseudo labeling scheme, which not only captures the model's generalization potential but"}
{"paper_id": 436, "abstract": "In the realm of distance metric learning (DML), the quest for embeddings that harmonize semantically similar samples can be fraught with peril. Traditionally, we have relied on global average pooling (GAP) to navigate this treacherous terrain. Yet, the intricate tapestry of these features often leads us to believe that each pixel represents a separate semantic entity.  In this paper, we embark on a quest to redefine GAP as an optimization problem, one that allows us to choose the subset of features to employ, as well as the weights to assign them while averaging. Our exploration reveals that the original GAP operates as a specific case of our proposed optimization problem for a certain realization. At the heart of our approach lies a zeroshot prediction loss, a clever regularization term that captures the essence of class labels as a convex combination of attribute embeddeddings.   To validate our findings, we introduce a synthetic empirical study, designed to validate the theoretical claims of our findings. The results reveal that our pooling method not only learns to choose better subsets but also enhances generalization ability. Our method can be applied to any DML loss, allowing us to harness the power of the pooling layer for generalization."}
{"paper_id": 437, "abstract": "In the ever-evolving landscape of machine learning, the quest for higher benchmark scores has led to a dramatic increase in the number of parameters in neural network architectures. This rise in parameters, while noble in its quest for efficiency, has posed a formidable challenge when it comes to harnessing the full potential of these larger structures. In the realm of training neural networks, the traditional method of pruning has emerged as a beacon of hope\u2014a method that seeks to reduce the parameters in a model while preserving its performance. Yet, this method has its own flaws, particularly when faced with the challenge of learning sparse neural networks (LTs) from scratch.  In this paper, we embark on a journey to redefine this pruning criterion, introducing a novel notion of layerwise importance. Our exploration delves into the intricacies of LTs, revealing a remarkable truth: it is not only possible but also possible to extract LTs with similar performance, yet differing significantly in their structure. Furthermore, these LTs possess a remarkable ability to maintain a stable number of common connections, a remarkable feat that stands in stark contrast to their more complex counterparts.    At the heart of our exploration lies the introduction of the LTH algorithm, a groundbreaking technique designed to extract"}
{"paper_id": 438, "abstract": "In the ever-evolving realm of machine learning, the challenge of instance segmentation has emerged as a formidable challenge, one that demands the mastery of deep, non-differentiable priors. This challenge is particularly pronounced in the realm of medical and biological imaging, where the need for high-level priors looms large and the training corpus is vast.  In this work, we embark on a quest to forge a framework that harnesses the power of stateless actor-critic (SAC) models to illuminate the path to end-to-end segmentation.  At the heart of our approach lies a novel SAC-based reinforcement learning framework, where rewards can be derived from a non- differentiable cost function.  Our method not only empowers the agent to predict the weights of the edges in the superpixel region adjacency graph, but it also empowers it to learn to approximate the rewards based on object-and image-level reasoning.   In our experiments, we demonstrate that our approach not only excels in segmentation with no supervision but also excels at predicting the optimal rewards for each instance.  To further illuminate our approach, we introduce a strategy for spatial decomposition of rewards, enabling localized supervision from combinations of"}
{"paper_id": 439, "abstract": "In the ever-evolving landscape of distributed computing, the quest for robustness has emerged as a formidable challenge. In this paper, we embark on a quest to unravel the intricacies of Byzantine adversarial training within the confines of a communication-constrained topology. At the heart of our exploration lies a novel network robustness criterion, designed to assess the resilience of decentralized training. This criterion is not merely theoretical; it is grounded in the intricate interplay between the topology and the number of attackers. Through rigorous experimentation, we unveil a novel defense strategy, dubbed CLIPPEDGOSSIP. This method not only withstands the onslaught of Byzantine attacks but also excels in achieving stochastic convergence rates that rival those of non-robust (Byzantine-free) non-convex optimization. Moreover, we demonstrate that our approach not only meets but surpasses the performance of traditional non-stochastic stochastically optimization methods, all while maintaining the robustness of our training strategy."}
{"paper_id": 440, "abstract": "In the ever-evolving landscape of network analysis, the quest for efficient and compact representations of shortest-path (SP) distances has emerged as a paramount challenge. Traditional approaches, such as the Dijkstra algorithm, often struggle to cope with the sheer size of large and complex graphs, leaving them vulnerable to prohibitive storage and response costs. In this exploration, we embark on a journey to forge a new path in SP representation\u2014a path paved with efficiency, accuracy, and speed.   Our exploration reveals a stark contrast between approximate (ours) and exact (PLL) SP representation methods, revealing a striking disparity in the storage costs associated with these methods relative to the size of their respective graphs.  In stark contrast, learning-based methods stand out for their efficiency, boasting high accuracy and short response times.  To illuminate this difference, we introduce a rigorous simulation of Bernoulli random graphs, each edge filled independently with probability p.(a). The results reveal that the storage cost of exact methods, particularly those that rely heavily on indexing or compressing techniques, can be prohibitively costly, particularly when faced with the demands of large, complex graphs. In contrast, the efficiency of approximate methods can be dramatically enhanced, allowing them to tackle"}
{"paper_id": 441, "abstract": "In the ever-evolving realm of machine learning, the quest for second-order optimization has emerged as a beacon of promise, illuminating a path forward in the realm of neural network training. Yet, as we embark on this journey, we face two formidable challenges: first, computing the curvature for a large and deep neural network, which is computationally burdensome, and second, training the actual network with gradient descent.  In this work, we unveil a novel approach: the introduction of Newton losses, designed to bridge the gap between first-order and second- order optimization. This innovative approach allows us to harness the power of both optimization techniques while training our neural network with first-ordered optimization.   Our experiments reveal that Newton losses not only enhance performance in the face of hard-to-optimize loss functions, but also maintain the original performance when faced with more straightforward losses. Furthermore, we conduct an empirical evaluation on two popular benchmarks, including the four-digit MNIST sorting benchmark and the Warcraft shortest-path benchmark.  Our findings reveal that the Newton losses we propose not only elevate performance but also enhance performance across a diverse array of algorithmic losses."}
{"paper_id": 442, "abstract": "In the ever-evolving realm of artificial intelligence, we unveil SeqSHAP, a groundbreaking method designed to unravel the intricate tapestry of sequential data and model predictions. This innovative approach is not merely an extension of existing post-hoc model attribution methods, but a groundbreaking approach of its own. At the heart of our approach lies a distribution-based segmentation method, crafted to capture the distribution information of sequential features. With this information, we then craft a series of distinct subsequences\u2014separate units that serve as independent units. Our experiments across two real-world transaction datasets reveal that this method not only offers intuitive explanations but also provides meaningful subsequences.  In this paper, we embark on an exploration of the implications of our method, revealing that it stands shoulder to shoulder with the best in the field of sequential model explanation."}
{"paper_id": 443, "abstract": "In the ever-evolving landscape of Chinese NLP, word segmentation stands as a crucial component. Yet, as we delve into the intricacies of word information, we find ourselves at a stalemate. While the recent development of the pre-training model has illuminated the path for word segmenting in Chinese, its performance remains shrouded in mystery. This paper introduces the boundary-enhanced decoder (BED), a novel approach designed to unravel the tangled tapestry of Chinese word information. In this approach, we first segment the sentence into words, then tokenize these words into more fine-grained pieces. This method not only streamlines the process of segmenting the sentence but also empowers the decoder to navigate the intricate landscape of OOV words.  To our knowledge, this is the first study of BED, and it stands poised to revolutionize our understanding of the word-segmentation challenge in Chinese.  In this paper, we embark on a quest to optimize the segmentation effect of our BED model, particularly when faced with the daunting challenge of OV words. We present our findings in the form of a series of experiments conducted on the Chinese Word Segmentation (CWS) challenge. The results of these"}
{"paper_id": 444, "abstract": "In the realm of generative modeling, diffusion probabilistic models (DDPMs) have emerged as a beacon of hope, heralding their prowess across a diverse array of domains. Yet, the true potential of these models remains shrouded in mystery, shrouded by the complexities of individual features and the small sizes of tabular datasets.  In this paper, we embark on a quest to unravel this mystery, unveiling the potential of TabDDPM, a novel design designed to tackle any tabular problem.  At the heart of our findings lies a simple yet powerful design: a model that can handle both numerical and categorical data, allowing it to adapt to a multitude of scenarios.  Our exploration leads us to a pivotal discovery: when faced with the challenge of training a high-quality model for tabular data\u2014a challenge that is as formidable as it is daunting for computer vision or NLP\u2014TabDDPM not only stands shoulder to shoulder with the best but also shines brightly in the face of competition.  To further illuminate this insight, we present a series of experiments across a variety of datasets, showcasing how TabDDP not only meets but surpasses the performance of existing state-of-the-art models but also sets a new benchmark in its ability"}
{"paper_id": 445, "abstract": "In the realm of generative flow networks (GFlowNets), we unveil a novel objective: subtrajectory balance (SubTB). SubTB, when employed with a real-valued hyperparameter, allows for a smooth interpolation between the high-bias, low-variance objective of the flow matching (FM) and detailed balance (DB) learning objective, while preserving the integrity of the stochastic gradient.  Our experiments reveal that SubTB() not only enhances convergence but also empowers models to navigate the intricate landscape of real-world scenarios.  At the heart of our approach lies a novel approach to temporal difference learning (TD), a technique that seeks to weave a tapestry of events into the fabric of a model\u2019s training process. Through a series of experiments across two synthetic and four real world domains, we demonstrate the benefits of SubTB."}
{"paper_id": 446, "abstract": "In the ever-evolving landscape of machine learning, the art of conformal prediction has emerged as a beacon of hope for those seeking to navigate the treacherous waters of distribution shifts. Yet, as we delve deeper into the realm of real-world applications, we uncover a formidable challenge: the challenge of calibrating conformal predictors only based on unlabeled examples from the target distribution.   In this exploration, we embark on a journey to calibrate our conformal predictor using only unlabelized examples from this target distribution, a challenge that is fraught with significant challenges. First, we introduce a simple recalibration method that deftly recalibrates conformal predictions for the worst-case distributions, ensuring that we achieve the desired coverage.  Second, we demonstrate that our recalibration method not only achieves near oracle-level coverage, but also significantly reduces the performance gap between our calibrations and those of previous calibrators. Finally, we present a rigorous empirical study on the performance of our method on a variety of ImageNet classifiers, revealing that it stands shoulder to shoulder with the best in terms of performance.  Our findings reveal a striking truth: when recalibrated against the target distributions, our method consistently outperforms the best calibrators"}
{"paper_id": 447, "abstract": "In the realm of federated learning (FGL), the quest to harness the power of graph neural networks (GNNs) to tackle the complexities of distributed subgraphs has proven to be a formidable challenge. Yet, the challenges of structure non-IID remain formidable, particularly when faced with the intricate tapestry of local subgraph distributions. In this exploration, we embark on a journey to unravel the intricate dance of subgraph structure through the lens of a federated federated model. We introduce a groundbreaking framework, the Adaptive Federated Graph Learning (AdaFGL) pipeline, designed to tackle this challenge head-on. At the heart of our framework lies a three-part approach: first, the global base, followed by two modules: one dedicated to subgraph homogeneity and one designed to address the heterogeneous nature of the subgraph. Finally, we introduce FedSage+, a module designed to enhance the performance of our federated models. This innovative approach not only harnesses the strengths of the GNNs but also empowers local clients with the ability to share node embeddings, enhancing the efficiency of our models.  The results speak for themselves: FedAdAFGL not only outperforms the existing feder"}
{"paper_id": 448, "abstract": "In the ever-evolving realm of machine learning, neural networks (NNs), the quest for human-centered explanations has emerged as a beacon of hope. Yet, as we delve into the intricate tapestry of neural networks, we find ourselves at a crossroads. The quest for global explanations for NN models is fraught with challenges, particularly in the realm of high-dimensional and complex data.  In this paper, we embark on a quest to forge a new path, introducing the concept of symbolic conceptual views (symbolic conceptual views) as a bridge between local and global explanations. Our exploration reveals that these conceptual views not only enhance understanding but also serve as a powerful tool for understanding the intricate relationships between neural networks and their surrogates.  Through rigorous experimentation, we demonstrate how these conceptual conceptual views can be harnessed to construct human-comprehensible propositional statements, drawing upon the knowledge gleaned from the NN's neurons. Moreover, we unveil how these representations can be seamlessly integrated into the training of surrogate training, allowing us to extract global rules through the lens of propositional logic.   The results of our experiments speak for themselves: our findings reveal that NN-trained surrogate training not only excels but also thri"}
{"paper_id": 449, "abstract": "In the ever-evolving landscape of machine learning, the challenge of bilevel optimization has emerged as a beacon of innovation, drawing the attention of researchers from a diverse array of fields, including reinforcement learning, hyper-parameter optimization, and meta-learning. Yet, despite its prominence, the landscape remains largely shrouded in mystery, with the majority of recent work focusing on either analyzing the convergence behaviors of the problem or seeking to improve its convergence rate.  In this paper, we embark on a quest to unravel the complexities of this intricate problem, offering a thorough analysis of its generalization behaviors through the lens of stochastic gradient descent (SSGD) and two-timescale optimization (TSGD). Our findings reveal a striking truth: the uniform stability of SSGD and TSGD is not merely the result of uniform stability, but rather a reflection of the intricate interplay between these two optimization strategies.  To illuminate this insight, we present a series of rigorous experiments across a variety of optimization settings, spanning the scales of SC-SC, C-C, NC-NC, and NC-SC. The results of these experiments reveal that the UD algorithm not only maintains uniform stability but also enhances it, demonstrating its prowess in the intricate realm of generalization"}
{"paper_id": 450, "abstract": "In the ever-evolving landscape of long sequence modeling, the quest for efficient attention mechanisms has emerged as a formidable challenge. Traditionally, researchers have relied on the Long Range Arena (LRA), a beacon of efficiency in the landscape of sequence modeling. Yet, the LRA is fraught with limitations, particularly when it comes to cross attention, a critical element in the intricate tapestry of real-world tasks.  In this paper, we embark on a quest to unravel the mysteries of efficient attention through the lens of the attention taxonomy, unveiling four distinct attention patterns\u2014noncausal self, causal self, noncausal cross, and causal cross. Our exploration delves into the intricacies of these attention patterns, revealing that they often diverge from one another.  To further illuminate our findings, we introduce the attention benchmark (CAB), a comprehensive framework designed to gauge the efficiency of attention mechanisms across a diverse array of tasks. Through rigorous experimentation, we demonstrate that CAB not only excels but surpasses the current state-of-the-art in terms of attention efficiency, demonstrating that it can be harnessed to tackle the challenges of long-context language modeling.  Moreover, we delve into the intricate interplay of interpolation and"}
{"paper_id": 451, "abstract": "In the ever-evolving realm of Reinforcement Learning, we unveil a groundbreaking approach: Action Discretization Variational Auto-Encoder (AD-VAE). This innovative method harnesses the power of reinforcement learning to forge discrete action representations without the need for any domain knowledge. At the heart of our approach lies a novel neural network, dubbed Neural Discrete Reinforcer Learning (NDRL), designed to tackle the intricate dance of action discretization in complex action spaces. NDRL employs a state-conditioned action encoder and decoder, coupled with a graph network and a soft-argmax neural network. Our approach not only empowers RL agents to navigate the complexities of action spaces with ease but also enhances the efficiency of exploration and the stability of RL agents.    In this paper, we embark on a quest to unravel the intricate tapestry of action representations, crafting a unified discrete action space from scratch. To tackle this challenge, we introduce a novel ensemble of action encoders and decoders, dubbed D-Concrete Action Remapping (Q-Con, or D-A). This method not only streamlines the learning process but also serves as a beacon of hope for the future of RL across diverse action"}
{"paper_id": 452, "abstract": "In the ever-evolving realm of machine learning, deep neural networks (DNNs) have emerged as a beacon of promise, capable of predicting the most probable outcomes from a vast array of images. Yet, despite their impressive prowess, they remain shrouded in mystery, shrouded in the shadow of their black-box nature.  In this paper, we unveil a groundbreaking approach to explainable DNNs: multilevel XAI. By harnessing the power of visual and linguistic attributes, XAI adeptly navigates the complexities of class-wise saliency maps. This innovative approach not only streamlines the learning process but also empowers practitioners with the ability to craft human-like explanations for the decisions they face. The results speak for themselves: our method not only enhances the accuracy of DNN predictions but also sets a new benchmark in the realm of explainable AI, paving the way for the creation of more nuanced and nuanced explanations.  At the heart of our approach lies two key principles: first, we employ per-class attributes, which are not as computationally burdensome as per-image bounding boxes; and second, we leverage linguistic salient attributes, both of which can be gleaned from the raw raw data.  Our findings reveal that"}
{"paper_id": 453, "abstract": "In the realm of numerical partial differential equations (PDEs), the pursuit of physics-informed neural networks (PINNs) has emerged as a beacon of hope. Yet, as we delve into the intricate tapestry of these networks, we find that they often falter when faced with a target function that contains high-frequency features. This phenomenon, known as the spectral bias, not only permeates the training of infinitely-wide PINNs but also permeates even the simplest linear PDEs.  In this paper, we embark on a quest to unravel the intricate dance of spectral bias within PINNs, revealing that it is not merely a phenomenon of the training process, but rather a critical component of the optimization process itself.   Our findings reveal that the neural networks that have been trained on a low-frequency PDE often fail to converge to the optimal solution when the target function is high in frequency, a phenomenon known as spectral bias.  To combat this, we introduce a novel optimization technique known as Gradient Gradient Optimization (GDM). This method is designed to harness the power of momentum, allowing the network to learn the target functions with a fraction of a second over time.  Our experiments reveal that GDM not only outperforms"}
{"paper_id": 454, "abstract": "In the realm of neural networks, the quest for non-pointwise nonlinearities often leads us down the path of pointwise (or \"local\") nonlinearity, where the same function, \u03c3, is applied to each coordinate independently.  In this paper, we unveil a groundbreaking approach: radial rescaling activations, which transcend the confines of the pointwise domain. This innovative approach allows us to harness the power of radial basis functions, a class of nonlinear activations that are not merely point-wise but also inherently universal.  Our exploration reveals that these networks not only possess a remarkable ability to approximate asymptotically affine functions but also exhibit remarkable compressibility, symmetry in optimization, and universal approximation. Moreover, we demonstrate that the compressed loss function of our compressed network is equal to the loss of the original model after each step of gradient descent.   In our second set of results, we delve into the intricacies of parameter space symmetries, uncovering a practical algorithm designed to compress the loss function for the compressed network, all while maintaining the same loss function on any batch of training data.  At the heart of our findings lies a novel neural network class: the Radial Rescaling Network (RNN"}
{"paper_id": 455, "abstract": "In the realm of distributed optimization, Federated Learning (FL) emerges as a beacon of promise, where clients' local gradients serve as the foundation for global optimization. Yet, as we delve deeper into the training dynamics of FL, we find a striking similarity between the centralized mini-batch SGD and the intricate dance of client coherence and global weight shrinking.  In this paper, we embark on a journey to unravel the nuances of aggregation weight optimization within FL, drawing inspiration from the insights gleaned from aggregation weights learned from clients' global gradients. Our exploration reveals a fascinating truth: aggregation weights serve as a powerful tool framework for understanding the dynamics of training dynamics in FL. By harnessing the power of aggregation weights, we forge a novel FEDAW algorithm designed to optimize the global weight of our aggregation model during the training phase of FL.  At the heart of our approach lies two critical insights: first, the importance of sample coherence; second, the influence of weight decay on the generalization performance of FL models.  Through our exploration, we unveil a novel aggregation weight algorithm, designed to navigate the treacherous waters of aggregation aggregation with grace and efficiency. Our findings reveal that aggregation weights not only enhance performance but also enhance the overall quality of the"}
{"paper_id": 456, "abstract": "In the ever-evolving realm of machine learning, where the quest for accuracy and efficiency reigns supreme, we unveil a groundbreaking approach: the Transformer-Based Transformer (BERT) architecture. This innovative approach harnesses the power of attention-based transformers, deftly weaving them into the fabric of text representation. At the heart of BERT lies a transformer for the text, followed by an embedding module for the meta-data. This module serves as a bridge, bridging the gap between the two, allowing us to train on both the text and its meta-dataset simultaneously.  Our experiments, conducted across a diverse array of data sets, reveal a striking truth: the BERT architecture not only excels at capturing the essence of text but also excels in capturing the subtleties of message classification.  To further illuminate the path forward, we introduce a block-based transformer architecture, designed to tackle the complexities of multiple text inputs. This method not only enhances the training of the model but also enhances its versatility, allowing it to adapt to a multitude of input types."}
{"paper_id": 457, "abstract": "In the realm of video-language pre-training (VLP), the quest for efficient and effective end-to-end (BERT) methods has emerged as a beacon of hope, heralding a new era of data-efficient learning. Yet, as we embark on this journey, we are faced with a formidable challenge: the intricate interplay of pre-extracted region features with the intricate tapestry of real-world words.   In this paper, we unveil a groundbreaking solution: bidirectional region-word alignment regularization. This innovative method not only enhances the performance of our state-of-the-art VLP model but also empowers it to seamlessly integrate into the vast array of downstream tasks.  At the heart of our approach lies a groundbreaking sub-optimal region regularization, which not only streamlines our model\u2019s performance but also ensures that it adheres to the strict constraints of domain and language modality.  Our findings reveal that this regularization not only empowers VLP to achieve superior downstream performances but also enhances its ability to model and promote cross-modality alignment.  The results speak for themselves: our model not only achieves superior performance on multiple downstream tasks but also surpasses the current state"}
{"paper_id": 458, "abstract": "In the realm of vertical federated federated learning (VFL), the quest for data privacy has become a formidable challenge, particularly in the intricate landscape of vertical bilevel optimization problems (VFBOs). Traditional stochastic Bilevel Optimization (BO) methods, while heralded for their prowess, often falter when faced with VFBO problems, such as hyper-representation learning and hyperparameter tuning.  Enter the JacoBian Estimator (BAMBI), a groundbreaking method that harnesses the zeroth-order (ZO) estimation technique to approximate the Jacobian matrix. This innovative approach allows all parties to collaboratively compute the hyper gradient, ensuring both privacy-preserving and computation-efficient performance. Yet, the challenge does not end there; it is not merely a matter of preserving label privacy but also ensuring convergence.  In this paper, we unveil two groundbreaking BAMBI methods, i.e. iBAM and BAM-DP, designed to navigate the treacherous waters of BFBO.   At the heart of our approach lies a groundbreaking label privacy guarantee, which ensures that only the intermediate gradients (rather than raw labels) are transmitted from the server to parties not"}
{"paper_id": 459, "abstract": "In the ever-evolving realm of multi-agent online learning, we embark on a quest to unravel the intricate dance of decision-making through the lens of Stackelberg games. These games, rooted in the intricate interplay of two players, often feature a leader-follower structure, where the leader chooses a mixed strategy, while the follower seeks to outshine him.  In this exploration, we delve into the intricacies of these games, unveiling a fascinating truth: when the leader adopts a no-regret algorithm, it converges to an equilibrium that aligns with this equilibrium. Yet, when the follower chooses to embrace the no-reaction strategy, the regret dynamics of the leader diverges significantly, leading us to question the wisdom of this approach. To illuminate this conundrum, we introduce a novel approach: a best-of-two-worlds algorithm designed to tackle both the adversarial and stochastic rewards of the multi-armed bandit problem. This innovative approach not only enhances the performance of our algorithm but also empowers us to explore the complexities of the bandit game through a fresh lens.  Our findings reveal that by employing a mean-based, regret-based algorithm, we can achieve a Stac"}
{"paper_id": 460, "abstract": "In the ever-evolving realm of optimization, we unveil OptCtrlOP, a groundbreaking approach to the optimization of optimal control problems (OCPs). This innovative approach eschews the traditional two-phase methodologies of numerical solvers and neural network-based solvers. Instead, we introduce an instance-solution operator perspective for OCP solvers, drawing inspiration from the intricate dance of direct mapping. This approach not only enhances the efficiency of numerical solutions but also empowers them to tackle arbitrary input-domain queries.   In this paper, we delve into the intricacies of the optimal control problem through the lens of differential equation-governed OCPs.  Our findings reveal that the OptCTOP method not only achieves superior precision but also demonstrates remarkable speedup, surpassing the current state-of-the-art solvers by a factor of more than 2,000. Furthermore, we demonstrate that OptCTop not only stands shoulder to shoulder with its predecessors in terms of efficiency but also stands head-and-shoulders above the current field of numerical optimization."}
{"paper_id": 461, "abstract": "In the realm of distributed learning, federated learning (FL) stands as a beacon of innovation, harnessing the power of a central server to harness the collective wisdom of a multitude of clients. Yet, as we delve deeper, we find that the landscape of FL is fraught with challenges, particularly when faced with the challenge of high degrees of system and statistical heterogeneity.  In this exploration, we unveil a groundbreaking framework, FedCL, designed specifically for FL, designed to address these issues.   At the heart of FedCL lies the concept of critical learning periods (CLs), a critical period during the FL training process that dictates the number of clients that can participate in each FL training round.  To navigate this uncharted territory, we introduce FedCL\u2014a novel framework that adapts the state-of-the-art FL method to accommodate these CL periods.  FedCL augments the existing FL method, allowing it to adapt to the changing nature of clients during each FL round. Our findings reveal that FedCL not only enhances the efficiency of FL but also enhances the robustness of the model itself. In this endeavor, we demonstrate that our approach not only meets but surpasses the performance benchmarks of existing FL methods."}
{"paper_id": 462, "abstract": "In the ever-evolving realm of machine vision, object-centric generative models (OCGMs) have emerged as a beacon of innovation, transforming the landscape of inference and prediction tasks. Yet, the vast landscape of unsupervised, unlabeled data remains largely unexplored.  In this paper, we unveil OBPOSE, a groundbreaking model designed to unravel the intricate tapestry of scene decomposition. This innovative approach is not merely a pose estimation tool; it infers information from an object's shape to reduce apparent variance and streamline the learning of the model's component in 3D.  At the heart of our approach lies the introduction of pose (i.e. location and orientation) as a novel inductive bias.   By employing a tightest bounding box that constrains the object\u2019s shape, we uncover asymmetries in its shape, which can be used to constrain object's orientation.  Our experiments reveal that OBPose not only excels in scene inference but also excels at scene generation and editing. In contrast, the current state-of-the-art in OGGMs, such as ObRF (Stelzner et al., 2021) and YCB (Johnson"}
{"paper_id": 463, "abstract": "In the realm of supervised learning, the art of crowdsourcing labels has emerged as a beacon of efficiency, efficiency, and speed. Yet, as we delve deeper into the landscape of crowdsourced datasets, we find ourselves at a crossroads. Traditional methods often rely solely on task difficulty and worker abilities, neglecting the complexities of the task itself.   In this paper, we embark on a quest to harness the power of the Area Under the Margin (AUM), which serves as a confidence indicator in an assigned label for each training task. The AUM is a weighted average of margins obtained during the learning process, reflecting the challenges faced by a learning procedure as it attempts to pinpoint a task to a label. Through rigorous experimentation, we demonstrate that the AUM can serve as a powerful ally against the pitfalls of ambiguous tasks.  Our findings reveal that the WAUM not only identifies ambiguous tasks but also identifies their associated features, allowing us to cull them from the learning pipeline. In this way, we streamline the process of generalization, ensuring that we do not waste valuable data points."}
{"paper_id": 464, "abstract": "In the ever-evolving realm of machine learning, the quest for self-supervised learning from dynamic visual input data\u2014videos\u2014has emerged as a beacon of promise. Yet, as we delve deeper into the realm of deep video SSL, we find a stark contrast with the intricate dance of human representation learning, where the self-awareness of semantic change and consistency reigns supreme. In this paper, we embark on a journey to redefine the boundaries of video SSL by harnessing the power of contrastive learning, drawing its inspiration from the intricacies of human visual perception. We first harness the presence of saccades as an indicator of semantic changes, employing this as a powerful tool for modeling the role of self-aware self-consciousness in representation learning. Second, we introduce contrastive contrastive reorganization, a method that deftly redistributes the learned representations, ensuring that the associations forged between perceptually similar representations remain strong. Finally, we harness the semantic consistency inherent in the input, carefully minimizing the prediction error (PE) during fixation.  Our experiments reveal that our approach not only improves the Top-1 video retrieval accuracy but also enhances performance on downstream tasks such as action recognition."}
{"paper_id": 465, "abstract": "In the ever-evolving landscape of multi-agent reinforcement learning (MARL), we unveil a groundbreaking approach: Skilled Population Curriculum (SPC). This innovative method harnesses the wisdom of a teacher to forge cooperative policies from scratch.  At the heart of SPC lies a three-pronged strategy: first, we introduce the teacher as a contextual bandit, where we harness the power of an RNN-based imitation model to generate the bandit's context. Second, we employ a population-invariant communication strategy, where each agent's message is treated as an individual word. Third, we leverage the skill framework in the student to foster transferable skills across a diverse array of cooperative tasks. Our results speak for themselves: SPC achieves state-of-the-art performance in several multi-particle tasks, such as the 5vs5 Football competition in Google Research"}
{"paper_id": 466, "abstract": "In the ever-evolving realm of deep convolutional neural networks (CNNs), the quest to unravel the intricate tapestry of learning tasks has proven to be a formidable challenge. At the heart of this quest lies the intricate relationship between the kernel of a deep neural network and the eigenfunctions of its hidden layers, which serve as the primary predictors of generalisation errors.  In this paper, we embark on a journey to unravel this spectrum, revealing that the neural network's generalisation abilities are intricately tied to the spectrum of its kernel.  Our exploration spans a diverse array of deep hierarchical CNNs, each equipped with its own unique set of neural networks, each trained on a unique target function. Through rigorous experimentation, we unveil a remarkable truth: the generalisation error of these deep CNNs can be harnessed with a mere fraction of the training points. This revelation not only validates our hypothesis but also sets a new benchmark for the understanding of generalization errors in deep networks.   In our exploration, we delve into the interplay between the network\u2019s kernel and the neural networks\u2019 hidden neurons, uncovering a fascinating insight: the network can learn with a fraction of its training points\u2014up to a fixed"}
{"paper_id": 467, "abstract": "In the realm of Open-World Instance Segmentation (OWIS), the quest for class-agnostic segmentation often feels like a daunting challenge. Traditional two-stage methods often falter when faced with the challenge of incomplete annotations, leaving them ill-equipped to navigate the complexities of the open-world landscape.  In this paper, we unveil a novel approach: the Transformer-based Open-world Instance segmentation method (TOIS). This method is designed to tackle this challenge head-on, deftly segmenting objects that are not labeled in the COCO dataset. At the heart of our approach lies a novel regularization module, designed to simultaneously predict both instance masks and a foreground map.  To combat this inconsistency, we introduce a cross-task consistency loss, which punishes instances that stray from their labeled counterparts.   Our experiments reveal that this consistency loss is effective, even when annotators miss many instances.  The results speak for themselves: our TOIS method consistently segments objects that have not been labeled in COCA. Moreover, it stands shoulder-to-shoulder with a semi-supervised OWIS method designed for the UVO dataset, demonstrating its prowess in segmenting these objects."}
{"paper_id": 468, "abstract": "In the realm of reinforcement learning, the quest for a stationary policy that maximizes the expected reward is a formidable challenge. This challenge is often referred to as the challenge of robust constrained RL, where the goal is to achieve a convergence to stationary points while maximizing the reward.  In this paper, we embark on a journey to unravel the complexities of this challenge, unveiling a novel approach: the robust primal-dual algorithm. By employing the Lagrange multiplier method, we forge a robust solution that not only meets but surpasses the challenges posed by the constrained policy optimization challenge but also proves its feasibility.  Our findings reveal that the set of robust visitation distributions for our robust problem is not only non-convex but also offers a unique insight into the nature of the optimal value function. This insight leads us to a compelling conclusion: the convexity of the robust visitation distribution is not the only factor that determines its robustness.   To further illuminate our findings, we introduce a robust smoothed gradient function, which not only enhances the robustness of our solution but also enhances its practical applicability. Through rigorous experimentation, we demonstrate that our robust algorithm not only achieves convergence to the stationary points but also exhibits remarkable resilience to the unpredictable whims of uncertainty. "}
{"paper_id": 469, "abstract": "In the ever-evolving realm of reinforcement learning, the quest to achieve maximum reward or minimize the costfoot_1 stands as a beacon of promise. Yet, lurking in the shadows of this promise lies a formidable challenge: the convergence of policy gradient methods on unstable RL problems. Traditionally, these methods have relied on the assumption of a bounded cost function and the Lipschitz property of the gradient.   In this paper, we embark on a quest to unravel this conundrum, unveiling a novel logarithmic mapping method designed to speed up the convergence rate of these gradient-based policies.  Our exploration begins with a formal definition of the unstable RL problem, which we define as one where the input actions lead to a temporal growing effect against the cost output.  Through rigorous theoretical analysis and rigorous experiments, we present a compelling case for our method, showcasing its prowess across a variety of LQR and non-LQR scenarios.  At the heart of our findings lies a simple yet effective pre-processing step: optimizing the loss function over the spectral norm of the controlled system. This clever preprocessing not only reduces the computation cost but also enhances the learning rate, ensuring a faster convergence rate.  To further illuminate our findings, we"}
{"paper_id": 470, "abstract": "In the ever-evolving realm of machine learning, we unveil a groundbreaking approach: the SLDD-Model. This innovative method harnesses the power of a sparse and low-dimensional representation to enhance the interpretability of deep neural networks. The key to its success lies in its focus on a limited number of features, ensuring that only a handful are considered per class. This ensures that we can delve into the intricacies of each feature, allowing us to unravel its meaning and align it with human concepts post-hoc.   To further enhance the model's global and local interpretability, we introduce a novel feature diversity loss function designed to ensure a diverse array of features within each class.  This innovative loss function not only reduces the number of redundant features but also enhances the overall accuracy of the model, particularly when faced with a single, sparse class that relies heavily on just a handful of features.  In this work, we demonstrate the efficacy of our method on four common benchmark datasets, including ImageNet-1K and ImageNet. Our findings reveal that several learned features for algorithmic decision-making can be directly connected to human attributes."}
{"paper_id": 471, "abstract": "In the ever-evolving realm of unmanned aerial vehicles (UAVs), the quest for precision control under the unpredictable winds of unknown dynamics (OdD) stands as a pivotal challenge. Previous data-driven approaches have sought to tackle the challenge by estimating the unknown dynamics, but the estimation accuracy and the performance of the controllers are limited by the environment domain shifts in tests.  In this paper, we unveil a novel control algorithm designed to ensure that UAVs maintain accurate control even in the face of these domain shifts. Our innovative approach, dubbed OoD-Control, is designed to provide a robust framework for adaptive flight control.  At the heart of our approach lies a simple yet powerful assumption: the bound on the prediction error remains constant over a certain range of perturbations, ensuring that our algorithm can maintain its performance even under the most unpredictable environments. Furthermore, we demonstrate that our method not only withstands the challenges posed by OoD dynamics but also boasts a remarkable capacity for generalization.  Our simulated results reveal that, under a variety of aerodynamic conditions, our algorithm not only achieves better control performance than the SOTA deep learning algorithm but also outshines the state-of-the-art"}
{"paper_id": 472, "abstract": "In the ever-evolving landscape of artificial intelligence, the quest to create a high-fidelity talking head video has emerged as a formidable challenge. The challenge stems from the intricate dance between the source image and the target video\u2019s dynamic motion, where the former often falters and the latter falters. Yet, the challenge is not merely a technical challenge; it is a profound one, one that transcends the boundaries of traditional modeling techniques. In this paper, we unveil a novel approach: the implicit scale conditioned Memory Compensation Network (MCNet). This innovative framework harnesses the power of a global spatial meta memory bank, designed to deftly navigate the complexities of facial appearance and appearance ambiguities.  At the heart of MCNet lies an implicit scale-conditioned memory bank (ISCM), designed to learn and transfer global representations. This memory bank serves as a repository for the transfer of global representations, deftly compensating for the imperfections that arise from the dynamic motion of the target image. The warped feature map generated from the estimated motion field queries the memory bank through a dynamic cross-attention mechanism, providing a refined compensated feature map for the final generation.   Through rigorous experimentation on two competitive talking head generation datasets, we demonstrate"}
{"paper_id": 473, "abstract": "In the realm of reinforcement learning, the quest to unravel the complexities of action spaces looms large, challenging even the most seasoned of champions. The task of retrieving an action from the vast expanse of a discrete action space can be daunting, particularly when confronted with the challenge of enumerating all its actions.  In this work, we unveil a groundbreaking approach: Listwise RL. This innovative approach empowers RL agents to navigate the intricate dance of action retrieval through the art of listwise selection.  Our method not only enhances the efficiency of RL but also empowers the retrieval agent to adapt its selection strategy over the course of training.   At the heart of FLAIR lies a cascaded DDPG framework, designed to train an actor to retrieve an action that aligns with the current list of candidates, while the critics are trained to maximize the environment reward.  The cascaded actor selects a candidate action for each list index while considering the state and the partially built list as its input.  Through this process, FLAIR learns to select the action that maximizes its associated critic\u2019s value, enabling it to optimize the environment rewards associated with that action.  To further enhance our approach, we introduce cascaded cascading DQN, a novel"}
{"paper_id": 474, "abstract": "In the ever-evolving realm of artificial intelligence, word embedding stands as a beacon of hope, illuminating the path to a more robust understanding of the world through the lens of semantic information. Yet, as we delve into the complexities of embedding, we uncover a curious truth: the more robust a model is, the greater the correlation between its visual representation and its semantic word vector.  In this paper, we embark on a journey to unravel the intricate interplay between semantic information and model robustness, drawing inspiration from two pivotal insights: the distribution of information and the structural relevance of word vectors. First, we examine the correlation coefficient between the visual representation of a natural image and its corresponding word vector under non-robust and robust models.  Second, we introduce the Conversational Adversarial Constraints (CACs), which serve to align the information from the word vector to the visual space. Through these rigorous methods, we demonstrate that the robustness of a model trained on adversarial examples not only withstands distribution shifts but also thrives in the face of structural changes.  Our findings reveal that, when a robust model is pitted against an adversarial attack, its visual representations fare far better than their semantic counterparts.  To further"}
{"paper_id": 475, "abstract": "In the ever-evolving realm of artificial intelligence, we find ourselves in the realm of pretrained foundation models, such as CLIP (Radford et al., 2021), DALL-E 2, and GPT-3. These models, while capable of mastering a multitude of tasks, often struggle to adapt to the constraints of mobile devices and tablets.  In this paper, we embark on a quest to illuminate the intricacies of knowledge distillation, a method that seeks to transfer the knowledge of these pretrained models to lightweight, taskspecific models.  Our exploration reveals a striking truth: distilling from CLIP does not yield the desired results. Instead, when faced with limited training data, the output of CLIP can falter, leading to misclassification, mislabeling, and mislabelings.  To illuminate this phenomenon, we introduce a novel approach: the introduction of a fine-tuning process within CLIP, designed to enhance its performance on the image classification task. This process not only enhances the accuracy of the CLIP network but also enhances its performance across a diverse array of tasks.   Our findings reveal that CLIP is more likely to be trained with a cross-entropy criterion, suggesting that it may be"}
{"paper_id": 476, "abstract": "In the realm of natural language processing, deep learning has emerged as a beacon of promise, heralding a new era of data-driven learning. Yet, as we delve into the complexities of indoor scene classification, we find ourselves confronted with a formidable challenge: the intricate dance of data acquisition, representation, and the utilization of visual commonsense knowledge.  Traditional approaches, such as symbolic representations, tend to rely heavily on hand-crafted representations, while traditional probabilistic logics rely on the intricate tapestry of formal logic.  In this paper, we embark on a journey to forge a hybrid approach, embedding a declarative representation of knowledge into the fabric of our neural network. Our approach is not merely theoretical; it harnesses the power of deep learning to tackle the intricate challenges of indoor scenes.  To achieve this, we introduce a groundbreaking joint-modal fusion framework, designed to harness the strengths of early-learning vector representations alongside a robust logical embedding. This innovative approach not only enhances the performance of existing deep learning methods but also empowers us to forge our own path forward.  At the heart of our approach lies a novel approach known as 'A-then-then' embedding, which allows us to converge on a unique"}
{"paper_id": 477, "abstract": "In the ever-evolving realm of video recognition, the challenge of overfitting looms large, especially when faced with datasets such as Something-Something V1 (Goyal et al., 2017) and Kinetics V1/V2 (Kay et al, 2017). While 3D-based methods have emerged as a beacon of innovation, their 2D counterparts often struggle to navigate the treacherous waters of temporal overfitting. In this paper, we unveil a novel data augmentation approach we call Ghost Motion (GM). This innovative method shifts channels along the temporal axis, deftly transferring motion information to adjacent frames. At the same time, we interpolate the original video to create a new video, a process we call \"ghost video\" This innovative approach not only enhances the generalization capabilities of existing video recognition methods but also enhances their generalization prowess. Furthermore, we introduce a hyperparameter to scale the logits before each frame, ensuring that the model does not overfit frames that lack the necessary semantic information.  Our extensive experiments across a diverse array of datasets reveal that GM not only improves the performance of the baseline model but also significantly enhances the accuracy of its calibration errors. Our approach is not merely a theoretical construct; it can be seamlessly integrated into existing video"}
{"paper_id": 478, "abstract": "In the ever-evolving landscape of graph representation learning, we find ourselves at a crossroads between node- and layer-based sampling methods. The node-based approach has long stood as a beacon of efficiency, while the layer-by-layer approach has proven to be a formidable adversary, particularly when faced with the challenge of the Neighborhood Explosion Phenomenon (NEP).  In this paper, we unveil a novel approach known as LABOR, designed to bridge the gap between these two approaches. This innovative algorithm harnesses the strengths of both node sampling and layer sampling techniques, weaving them into a tapestry of efficiency and speed.  At the heart of our approach lies a unique hyperparameter, which serves as a guiding light, ensuring that each node is sampled with equal number of vertices. This ensures that the node samples at each layer are not only representative but also representative of the entire graph.   To validate our findings, we have conducted a series of experiments across a diverse array of graph datasets, spanning a variety of scales. The results speak for themselves, showcasing the superiority of LABor over its predecessors."}
{"paper_id": 479, "abstract": "In the realm of convolutional neural networks (CNNs), padding has emerged as a powerful ally, weaving itself into the fabric of model design. Yet, as we delve into the intricate tapestry of positional information, we find ourselves confronted with a formidable challenge: how to quantify the presence of this positional information?  In this paper, we embark on a quest to unveil the elusive Position-information Pattern from Padding (PPP), a persistent pattern embedded in the model features to retain positional information.  At the heart of our endeavor lies the notion that PPP emerges through the distributional difference between optimally-padded features and those that are algorithmically padded.  To unravel this mystery, we conduct a series of rigorous experiments, each meticulously documenting the formation of PPP across a diverse array of training settings. Our findings reveal a remarkable truth: PPP can be discerned with a mere handful of samples, revealing a pattern that stands apart from the noise and noise patterns of traditional padding schemes. To combat this phenomenon, we introduce ResNet50, a robust, robust, and adaptable model designed to navigate the treacherous waters of stochastic learning. Our experiments reveal that the ResNet model not only withstands the rigors of training but"}
{"paper_id": 480, "abstract": "In the realm of long-horizon robotic learning, the quest for abstract-to-executable policies has emerged as a beacon of innovation. Traditionally, a high-level planner crafts a kinematics motion plan, while a low-level controller executes it step-by-step in the physical realm. Yet, as we delve deeper, we find that this two-level dichotomy often falters in the face of the complexities of real-world tasks. For instance, the intricate dance of motion control requires the planner to navigate a complex state/action space, a task that often feels like a labyrinth. In this paper, we unveil TRajectory TRanslation (TR 2), a groundbreaking framework designed to bridge this gap. By harnessing the power of learning, TR 2 adeptly translates abstract trajectories into executable ones, all without the need for perfect alignment between high-dimensional states and low-dimensional executors. This innovative approach is not merely theoretical; it is grounded in the principles of Reinforcement Learning (RL). TR 2 not only empowers robotic agents to learn abstract policies but also empowers them to execute them in a manner that is both practical and efficient. To illustrate our approach, we introduce a simple Box Pusher task"}
{"paper_id": 481, "abstract": "In the ever-evolving realm of machine learning, we unveil a groundbreaking approach: the Bifold Embedded Data Ordered Neural Network (kaBEDONN). This innovative framework harnesses the power of relevant data to provide an explanation for a model prediction.  At the heart of our approach lies a simple principle: the relevance of data can be defined in three distinct ways. First, it can be deemed relevant when its features are \"similar\" to those of a training data sample. Second, it has the potential to be a powerful tool for improving the accuracy of model predictions. Third, it offers a robust framework for adjusting the order of data within the network, allowing developers to adjust the structure of the network based on user feedback.  Our experiments reveal that this approach not only enhances performance but also enhances the quality of the explanations provided to users."}
{"paper_id": 482, "abstract": "In the realm of reinforcement learning (RL), the Bellman operator (PBO) stands as a beacon of efficiency, capable of estimating the true value function of a given state with remarkable precision. Yet, when faced with the complexities of real-world problems, the PBO becomes a formidable ally, illuminating the path forward in the quest for value estimation.  In this paper, we embark on a journey to redefine PBO, introducing a novel approach that harnesses the power of samples to glean the optimal value function from the action-value space. Our approach is not merely theoretical; it has been proven to yield remarkable results across a diverse array of RL challenges.    To illuminate its potential, we introduce a groundbreaking value estimation algorithm designed to harness the potential of PBO. This innovative technique not only enhances the efficiency of value estimation but also offers a fresh perspective on how PBO can be harnessed to enhance the performance of existing value estimation methods, such as approximate value iteration (AVI).  At the heart of our approach lies the concept of projected Bellman operators, which are defined as functions defined by the parameters of the value function. These functions, rather than relying on the traditional projection step, are anchored in the action space, allowing us"}
{"paper_id": 483, "abstract": "In the ever-evolving realm of text-to-image synthesis, text-guided image generation models have emerged as powerful tools, capable of generating high-quality images from a diverse array of domains and styles. Yet, as we delve into the intricate tapestry of these models, we uncover a troubling truth: they can be manipulated by the mere presence of a single homoglyph, a mere substitution of a Latin character with a non-Latin one. This subtle change not only disrupts the natural flow of image generation but also introduces cultural biases into the fabric of the generated images.   In this exploration, we embark on a quest to unravel the intricate relationships that bind these models to specific character encodings, revealing that they are sensitive to the subtle nuances of these characters.  Our findings reveal that these biases can be harnessed by malicious parties, rendering the entire process meaningless. Moreover, we introduce a novel unlearning procedure designed to ensure that existing text encoders are not affected by these cultural biases. Through rigorous experimentation, we demonstrate that this unlearning process not only minimizes the impact of these biases but also enhances the resilience of existing encoder methods.  The results of our experiments reveal a striking truth: these models are not merely"}
{"paper_id": 484, "abstract": "In the ever-evolving realm of machine learning, we unveil a groundbreaking approach to learning Additive Noise Models (ANM) with Gaussian noise. These models, while recognizable for their causal directions, can also be loosely associated with functions that are not linear, allowing for the seamless integration of variational inference.  In this paper, we embark on a quest to harness the power of these non-linear ANMs through a rigorous derivation of the Variational Evidence Lower Bound (ELBO), drawing inspiration from the principles of a Variational Auto-Encoder (VAE). Our approach is not merely theoretical; it is grounded in rigorous empirical evidence, ensuring that we can infer the causal relationships between variables through the lens of a covariance matrix. At the heart of our approach lies a clever linearization method, leveraging automatic differentiation to construct a local Gaussian approximation for arbitrary ANMs.  We then introduce a temporal-aware specialization of the causal ANM, crafting a structure that encodes causal directions implicit in the arrow-of-time.  Our experiments reveal that our approach not only meets the rigorous requirements of the EELBO but also excels at fitting latent variables with a dependence structure in high-dimensional data, such as synthetic image and video"}
{"paper_id": 485, "abstract": "In the ever-evolving realm of multi-object tracking, we unveil a groundbreaking approach: Hierarchical Part-Whole Attention (HiPWA). This innovative approach harnesses the power of the attention mechanism from transformers to uncover distinguishable and discriminative visual representations for objects of interest. At the heart of HiPWA lies a three-level hierarchy: body parts, full body, and the union area, which we term the \"Part-Body-Union\" hierarchy.    Our exploration reveals that each level possesses its own unique value, allowing us to leverage the salient information within the body area while discarding the noise revealed by the contextual contrast.  Through rigorous experimentation across multiple multiobject tracking datasets, we demonstrate that our method achieves comparable or even better performance than the state-of-the-art transformer-based methods. Moreover, it boasts a more lightweight implementation and better time efficiency during training and inference."}
{"paper_id": 486, "abstract": "In the ever-evolving realm of Natural Language Processing (NLP), we embark on a quest to unravel the shadows of representational biases woven into the fabric of large-scale Pre-Trained Language Models (PTLMs). These models, which have emerged as formidable champions in the realm of natural language processing, possess a remarkable ability to predict the probability of a sequence of words for a given language. Yet, as we delve deeper, we find that these models often exhibit a troubling tendency to associate specific individuals or groups with negative perceptions. These negative perceptions are often the result of microaggression, stereotypes, or implicit hate speech in the pre-training corpus of large language models.   In this exploration, we unveil a groundbreaking metric designed to quantify these representational harms within 24 well-known PTLMs. Our findings reveal a striking correlation between the representational harm in these models and their performance on NLP tasks.  At the heart of our approach lies a clear conceptualization of the harmful effects of these representations, which we extend to a spectrum of 13 marginalized demographics. Furthermore, we delve into the network architecture of each PTLM, examining its correlation to existing metrics and network architecture.  Through this lens, we demonstrate that the representations we"}
{"paper_id": 487, "abstract": "In the ever-evolving realm of machine learning, self-supervised contrastive learning (CL) has emerged as a beacon of innovation, boasting remarkable prowess in learning generalizable representations from unlabeled datasets. Yet, amidst this promise, a critical question remains: how well do these algorithms fare in the face of data corruption? In this paper, we embark on a quest to unravel the complexities of pre-training data corruptions, unraveling the mysteries of how these changes affect the performance of these algorithms. Our findings reveal a striking truth: pre-trained CL models are not only more robust to downstream data corruption, but also more resilient than their supervised counterparts.  At the heart of our findings lies a simple yet profound insight: the learning process itself, rather than the data itself, determines the robustness of these models.  To further illuminate our findings, we delve into the intricate interplay of feature space metrics, uncovering a striking correlation between pre- training data and the overall performance of CL models. In this way, we illuminate the intricate dance of feature uniformity and stability that occurs during pre-processing. Our explorations reveal that the instance-level objective of CL may not be confined to semantic classes, but rather can be tailored to capture"}
{"paper_id": 488, "abstract": "In the ever-evolving realm of real-time applications, the challenge of two-stage classification stands as a formidable challenge. Traditional methods, such as Mendes et al. (2020) and Qi et al (2019), have sought to forge closer connections between classifiers in a multi-stage system. Yet, these methods tend to focus on the accuracy of classification rather than the latency of classification decisions.  In this paper, we unveil a novel training framework designed to bridge the gap between these two stages. At the heart of our framework lies a lightweight Pre-classifier, trained in the reverse order of inference, which serves as a guiding force for the Main Classifier. By employing a sample weighting method, we enable the Pre to learn according to its preference.  Our empirical evaluations reveal that our method not only surpasses the performance of baseline classifiers but also outstrips them in a variety of scenarios.   In a series of rigorous experiments, we demonstrate that our framework not only excels but also surpasses its predecessors in terms of performance and performance"}
{"paper_id": 489, "abstract": "In the realm of reinforcement learning, where the quest for effective policies often feels like a daunting journey, a teacher emerges as the guiding force, wielding a formidable arsenal of tasks to train a student agent. Yet, the task of crafting the full spectrum of tasks is fraught with challenges, particularly when it comes to the intricacies of the real-world. Traditional approaches, like PAIRED (Dennis et al., 2020) and Goal GAN (Florensa et al, 2018b), have emerged as the most effective tools for automating task generation. However, they falter when confronted with the challenge of training the student on tasks that fall outside the student's boundaries.   In this work, we unveil ZONE, a groundbreaking framework designed to formalize and operationalize the objective of ZPD-based teaching. Our exploration begins with the exploration of the relationship between the difficulty of tasks within a student\u2019s zone of proximal development (ZPD) and their potential to accelerate student learning.  At the heart of ZONE lies a dual purpose: to guide the teacher to generate tasks within this zone, ensuring that the student learns to tackle the tasks that are within their limits. To achieve this, we introduce two innovative techniques: RE"}
{"paper_id": 490, "abstract": "In the ever-evolving realm of Natural Language Processing (NLP), the quest for compact and efficient language models has led us to the realm of Knowledge Distillation (KD) approaches. Yet, as we embark on a quest to unravel the mysteries of knowledge distillation, we find ourselves at a crossroads. Traditional multi-teacher learning approaches often falter when faced with the challenge of distillation.  In this paper, we unveil a groundbreaking approach known as AutoSKDBERT, designed to harness the power of multiple teachers, each equipped with an optimized categorical distribution. This method is designed to distinguish effective teachers from ineffective ones through the lens of phase-1 optimization.  To further illuminate our findings, we introduce a deep convolutional neural network, distilled from the principles of deep learning. This neural network honours the effective teachers in phase-2 optimization, while optimizing the ineffective ones for phase-3 optimization. The results of our experiments, conducted on the GLUE benchmark, shine a light on the potential of this innovative approach."}
{"paper_id": 491, "abstract": "In the ever-evolving realm of machine learning, the quest for domain-invariant representations has long been a formidable challenge. Traditionally, we have relied on a dual-branching network to weave together the intricate tapestry of class and domain features, a process that often leads to entangled features that hinder the model's progress to new domains.  In this paper, we unveil a novel approach: the Random Style Sampling (RDS) scheme, designed to harness the power of random style statistics to enhance the diversity of domain-specific representations. Through rigorous experimentation, we demonstrate that RDS not only enhances the feature independence but also enhances its robustness, enhancing the model\u2019s ability to adapt to new environments.  To ensure that our approach not only meets but surpasses existing state-of-the-art methods, we introduce a series of innovative loss terms designed to ensure that the target branch remains tethered to its original representations, while the domain branch is not.   At the heart of our approach lies a simple yet effective regularization scheme, which serves as both a benchmark and a catalyst for the creation of new domain representations. This regularization not only ensures the original representations but also empowers the augmentation strategy to"}
{"paper_id": 492, "abstract": "In the ever-evolving realm of self-supervised learning, the quest for a sustainable framework has emerged as a formidable challenge. While the current state-of-the-art has proven its mettle in the realm of unsupervised representation learning, it faces a daunting challenge in harnessing the power of a pretrained SSL model\u2014one that often falters in the face of the demands of downstream tasks.  In this work, we embark on a quest to forge a new SSL model that not only surpasses its pretrained counterpart but also empowers it to navigate the complexities of the intricate tapestry of semantics. To achieve this feat, we introduce a novel approach: the mask-reconstruction scheme, where the base model generates reconstruction targets from the full input, and the new model learns to predict these targets from randomly masked image input. This method not only enhances the model's performance but also enhances its adaptability, allowing it to adapt to the nuances of various downstream tasks with remarkable efficiency.   To further illuminate our journey, we unveil a novel method that harnesses the knowledge gleaned from the pretrained base model, allowing us to adapt our new model's predictions to those of different base models. This innovative approach not only em"}
{"paper_id": 493, "abstract": "In the ever-evolving realm of room acoustics, we unveil SoundNeRirF, a groundbreaking receiver-to-receiver (R2r-RIR) neural network that adeptly predicts the sound waves that will emanate from any given spatial position.  At its core, this neural network operates as a continuous 6D function, weaving together a sparse set of 3D spatial positions that robots have explored, as well as the sound recorded by the robot at each point. This method not only captures the essence of the sound, but it also empowers the receiver with the ability to discern the reverberation of sound waves at any given point.   At the heart of our approach lies a unique neural network, which not only learns to predict the sound wave but also hones in on the intricate interactions between sound sources and receivers. Through this method, we forge a path forward in the realm of sound prediction, paving the way for a new era of machine learning.  In our experiments, we demonstrate the power of our R2R-R IR, boasting a remarkable ability to predict sound waves without the need for any prior knowledge of sound sources or room acoustic properties. Moreover, we introduce a robust physical constraint strategy, ensuring that our"}
{"paper_id": 494, "abstract": "In the ever-evolving realm of sound analysis, where the intricate dance of sound collides with the intricate tapestry of time and frequency, the challenge of sound counting stands as a beacon of promise. Yet, despite its potential, the quest for sound counting remains shrouded in mystery, shrouded in the shadows of over-solutioning sound event detection methods.  In this paper, we unveil a novel approach: a groundbreaking dyadic decomposition neural network designed to extract the cardinalities of sound waveforms directly from the raw waveform. This innovative approach not only empowers the neural network to learn a robust sound density representation but also empowers it to navigate the complexities of time-frequency variance, time-concurrence and spectrum-overlap.   To tackle these formidable challenges, we introduce a groundbreaking energy gain normalization module designed to regularize each intermediate parent waveform before feeding it to two child filters for further processing.  Through rigorous experimentation across four cross-domain sound datasets, we demonstrate the feasibility of our approach, showcasing the robustness of three polyphony metrics: polyphony ratio, maximum polyphony, polyphony mean ratio, and polyphony variance.  The results of our experiments reveal that our method not only meets the rigorous"}
{"paper_id": 495, "abstract": "In the ever-evolving realm of visual navigation, we unveil a groundbreaking framework: Active Topological Mapping (ATM). At its core, ATM harnesses the power of visual place recognition (VPR) to forge a topological map that is both efficient and efficient. At the heart of ATM lies two distinct stages: the first is active exploration, where the agent learns to navigate a new environment through a metric-free policy, and the second is the creation of the map itself, which is forged from the insights gleaned during this exploration.   In the first stage, we introduce a novel feature-space model, designed with the aid of the task and motion planning formalism (TAMP) and imitation learning. This model empowers the agent to conjure the best features from current and historical images, guided by the wisdom of our motion planner. The second stage, where we harness the data gleaned from VPR, crafts the map, weaving together the threads of local observations into a seamless tapestry. Through rigorous validation across a diverse array of photo-realistic and MP3 datasets, we demonstrate that ATM not only meets but also surpasses the performance of existing state-of-the-art topological maps in both visual exploration"}
{"paper_id": 496, "abstract": "In the ever-evolving realm of machine learning, we unveil the Neural-Symbolic Recursive Machine (NSR), a groundbreaking approach that harnesses the power of perception, syntax, and semantics to achieve remarkable generalization accuracy across a diverse array of datasets.  At the heart of NSR lies a groundbreaking modular design, crafted to seamlessly integrate the learning of each module within the Grounded Symbol System (GSS). The GSS emerges from training data without the need for domain-specific knowledge, allowing NSR to weave together the intricate tapestry of symbols through the lens of inductive biases.    In this exploration, we introduce a probabilistic learning framework designed to guide the model through the intricate dance of deduction, deduction, and semantic reasoning.  Our experiments reveal that NSR not only achieves state-of-the-art performance on SCAN, PCFG, and HINT, but also demonstrates remarkable transferability to existing neural-symbolic approaches.  The results are indisputable: NSR surpasses the performance of traditional neural networks on all three of these benchmark datasets, achieving a remarkable 100% generalization success rate."}
{"paper_id": 497, "abstract": "In the ever-evolving realm of Generative Adversarial Networks (GANs), the quest for inversion has become a formidable challenge. Traditionally, the quest has relied on per-image optimization, a laborious endeavor that often leads to information loss.  In this paper, we embark on a journey into the realm of high-rate inversion, harnessing the power of the wavelet transform to combat the distortions inherent in these per-frequency sub-bands. Our findings reveal that the widely-used loss term in GAN inversions, i.e., L 2, is biased toward the low-frequency portion of the spectrum.   To counter this bias, we introduce WaGI, a groundbreaking wavelet-based GAN model that deftly navigates the complexities of both frequency and spatial information. Through a clever wavelet fusion technique, we amplify the loss of the high-frequency segment of L 2 by amplifying the coefficients from the original image.  At the heart of our approach lies a novel interpretation of the loss term, which we call SWAG. This innovative technique not only enhances the accuracy of SWAG but also enhances its versatility, allowing it to adapt to a diverse array of image formats.  To further enhance our"}
{"paper_id": 498, "abstract": "In the ever-evolving realm of video highlights detection (VHD), we unveil the Global Prototype Encoding (GPE), a groundbreaking model designed to learn new highlight concepts incrementally, while retaining the lessons learned from previous examples.  At the heart of GPE lies a two-step approach: first, GPE extracts frame-wise features using a CNN, then employs a transformer encoder to aggregate the temporal context to each frame feature, leading to two distinct groups of learnable prototypes: highlight prototypes and vanilla prototypes.  Through this innovative approach, we harness the power of distance-based classification loss under L 2, allowing GPE to learn from a diverse array of highlight domains, all while preserving the knowledge gleaned from previous instances.  In this exploration, we delve into the LiveFood dataset, a rich tapestry of high-resolution videos spanning four distinct domains: cooking, eating, presentation, and moment localization. Through rigorous experimentation, we demonstrate that GPE not only excels on highlight detection accuracy (mAP) but also excels in training efficiency, achieving an impressive 1.57% on average.    To further illuminate GPE's capabilities, we propose a novel end-to-end model for incremental VHD learning"}
{"paper_id": 499, "abstract": "In the ever-evolving realm of deep learning, the exploding/vanishing gradient problem has emerged as a formidable foe, one that threatens the very fabric of neural network architecture. Traditionally, this problem has been relegated to the realm of batch normalization and ReLU-like activation functions. Yet, a surprising revelation has emerged: Gradient explosion occurs even when these methods are employed. In this study, we embark on a journey to unravel the intricacies of this phenomenon, revealing that it is not merely a passing fad. Rather, it is a fundamental truth of deep neural network training, a phenomenon that arises during the early stages of training. Our findings reveal a striking correlation between the rate of gradient explosion and the expected sampling error of the batch-normalization procedure.  To our knowledge, this is the first study to delve into the intricate interplay between activation functions and batch normalizations, illuminating the path of solution. The results reveal a fascinating truth: when the activation function is not used, the training instability becomes more pronounced. This insight leads us to a novel approach: the use of residual connections to mitigate the exploding gradient during training. This method not only alleviates the problem during training but also navigates its way through the uncharted waters of"}
{"paper_id": 500, "abstract": "In the realm of organic chemistry, where the quest for synthesizing molecules is a formidable challenge, retrosynthetic planning emerges as a beacon of hope. Here, the quest begins with the discovery of a series of starting molecules, followed by a sequence of reactions designed to synthesize the target molecule. This journey is not merely a journey through the landscape of single-step reactions; it is a journey of multi-step processes, where we seek to unravel the intricate tapestry of molecules through the lens of a reaction graph.  In this work, we embark on a quest to forge a new benchmark, one that harnesses the power of the memory-enhanced Transformer with an additional memory module.  Our exploration reveals a remarkable truth: the number of steps involved in synthesizing a molecule can be a powerful metric for estimating its synthetic accessibility.  To illuminate this insight, we introduce the Metro Transformer, a groundbreaking framework that captures the context information embedded in the reaction graph, allowing us to control the search within a reasonable reaction space. Through rigorous testing across a diverse array of target molecules, we demonstrate that Metro not only meets but surpasses the performance of existing benchmark models in terms of top-1, top-2, and top-3,"}
{"paper_id": 501, "abstract": "In the realm of spatial exploration, we unveil a groundbreaking framework we call Fragmentation-and-Recall (FAR). This innovative approach harnesses the power of online clustering to craft local models from the chaos of procedurally generated spaces. When faced with a complex world, it can be more efficient to build a series of local models rather than a single global model. Facing the challenge of complex spaces, we propose that these local models can serve as a bridge, guiding the agent through the intricate dance of exploration. When confronted with a challenge that demands more than one local model, we suggest that the agent adapts its current local model to accommodate the complexities of the space it seeks to explore. At the heart of our approach lies a curiosity-driven reinforcement learning setting, where we introduce FarCuriosity, a module designed to guide the agent toward its next observation. Through this process, we establish a framework for FAR exploration, which we call FarMap. FarMap is designed to navigate procedurally-generated spatial environments with less memory usage and a fraction of the time it would take to traverse traditional baselines. By contrast, FARCuriosity boasts a remarkable advantage, navigating the vast expanse of space with less than half the memory usage. "}
{"paper_id": 502, "abstract": "In the ever-evolving realm of computer vision, heterogeneous image transformation has emerged as a formidable challenge. This challenge is not merely a theoretical challenge; it is a practical one, one that demands the creation of 3D scene models and the acquisition of complete material information. In this paper, we embark on a quest to tackle this challenge through the lens of image transformation model learning, a groundbreaking technique that harnesses the power of deep convolutional neural networks. Our exploration focuses on the Multispectral Pedestrian Detection (MPD) dataset, published by the Korea Advanced Institute of Science and Technology (KAIST). The KAIST-MPD dataset is the only publicly available dataset that contains a vast array of visual and infrared approximate common aperture images, spanning a multitude of scenes.  At the heart of our approach lies a four-layer multi-scale encoder generator, designed to capture the structural information of an arbitrary function. This generator is comprised of three layers, downsampled three times, and decoded from small to large in turn.  Two structure-sensitive loss functions are introduced to tackle the challenges posed by L1 loss and generative adversarial loss, both of which fail to effectively constrain the information contained in a single"}
{"paper_id": 503, "abstract": "In the ever-evolving realm of protein folding, a new generation of generative models has emerged, harnessing the power of inter-residue angles to generate biologically plausible protein structures. Yet, as we delve deeper, we find ourselves at a crossroads, faced with a formidable challenge: the creation of structures that are both computationally efficient and physically foldable.  In this work, we embark on a quest to tackle this formidable challenge head-on. We introduce a novel approach: the diffusion probabilistic model (diffusion model). This innovative framework, inspired by the in-vivo folds of protein backbones, is designed to harness the inherent dynamical properties of these structures.  Through rigorous empirical validation, we demonstrate that this model not only captures the essence of protein structure but also achieves a remarkable level of robustness.   Our findings reveal that this innovative approach not only meets but surpasses the expectations of traditional generative adversarial networks (GANs) but also surpasses them in terms of overall performance.  To illustrate our findings, we present a suite of quantified samples from our model, each meticulously crafted to capture the natural distribution of interresidues. The results speak for themselves: our backbones are not only"}
{"paper_id": 504, "abstract": "In the ever-evolving realm of machine learning, the quest for generalization has long been fraught with challenges, particularly when it comes to the intricate intricacies of model architecture and hyperparameters.  In this paper, we unveil a groundbreaking framework designed to quantify the inductive bias complexity of a task, revealing the true depth of its inductive biases.  To our knowledge, this is the first quantifiable measure of inductIVE bias complexity, a measure that quantifies the fraction of the entire hypothesis space that falls within the bounds of the training data.  Our findings reveal two critical insights: first, that partially observed environments often require far greater inductives than fully observed ones; and second, that even simple meta-learning tasks, such as those in the realm of supervised learning, can require more inductives.   To further illuminate our findings, we introduce a practical algorithm designed to measure and compare the inductives of tasks across the domains of supervised Learning, RL and few-shot Meta-learning."}
{"paper_id": 505, "abstract": "In the realm of deep generative models (DGMs), we embark on a quest to unravel the secrets of graph disentanglement. This quest begins with the challenge of unsupervised graph editing, where the quest for graph controllable generation becomes a quest fraught with uncertainty.  In this paper, we unveil a groundbreaking framework, dubbed GraphCG, designed to tackle this challenge head-on. Our exploration reveals that the latent space of DGMs in graph data is not always perfectly disentangled.   To navigate this uncharted territory, we introduce Graph CG, a model-agnostic and task-agnestive framework designed to harness the potential of graph data.  Through rigorous experimentation, we demonstrate that Graph CG not only captures the essence of these latent spaces but also navigates them in a manner that is both efficient and efficient.  To validate our findings, we conduct an empirical study of the latent spaces of two common graph data types: molecular graphs and point clouds. Our findings reveal that the learned representations of these data types are not perfect; they often falter when faced with a pretrained DGMs.  Thus, Graph CG stands as a beacon of hope for the untapped potential of DGM-based graph editing. "}
{"paper_id": 506, "abstract": "In the ever-evolving realm of image classification, the quest for cross-model compatibility often comes at the expense of accuracy. In this paper, we embark on a quest to forge a new path: Positive-Congruent Training (PC-Training). This innovative approach seeks to minimize negative flip rates (NFRs) while simultaneously lowering the error rate (ERs). In this endeavor, we delve into the intricacies of negative flips, uncovering their root causes, and lay the groundwork for a model update that achieves this dual goal.  At the heart of our investigation lies a deep ensemble approach that seeks to reduce NFRs while simultaneously enhancing accuracy.  But, as we delve deeper, we discover that this approach is not viable in real-world applications. It imposes a burden on post-processing resources, leading to a significant increase in the cost of PC-training. Instead, we propose a method that harnesses the power of ensemble training. This method not only reduces NFR but also empowers PC-trained models to improve accuracy, all while maintaining the integrity of their ERs."}
{"paper_id": 507, "abstract": "In the ever-evolving realm of optimization, the quest for optimal transport has emerged as a beacon of innovation, heralding a new era where the art of amortized optimization reigns supreme. Yet, as we embark on this journey, we face a formidable challenge: how can we predict the solutions to optimal transport problems? Enter the Meta Optimal Transport (Meta OT) framework, a groundbreaking approach that harnesses the power of machine learning to forge solutions from the very essence of input measures (\u03b1, \u03b2). This innovative approach is not just theoretical; it can be deployed in real-world scenarios, where it not only meets the challenges of optimal transport with ease but also excels in predicting its solutions.  In this paper, we delve into the intricacies of Meta OT, unveiling a series of innovative algorithms designed to bridge the gap between discrete (sect.3.1) measures and their continuous counterparts.  Our findings reveal that Meta OT not only surpasses the current state-of-the-art in solving these optimization problems, but it also significantly reduces the number of iterations required to solve eq. (1) between discrete and continuous measures. Furthermore, we demonstrate that our Meta OT methods can be employed in the realm of single-cell pert"}
{"paper_id": 508, "abstract": "In the ever-evolving realm of machine learning, the Transformer has emerged as a beacon of efficiency, wielding the power of attention with remarkable efficiency. Yet, its prowess is not without its limitations, as its computational complexity spirals out of proportion to the length of the sequence.  In this work, we unveil a groundbreaking architecture we call neural attention memory (NAM). This innovative architecture reimagines the attention mechanism as a simple read-and-write mechanism, leveraging a memory matrix to store key-value pairs.  At the heart of NAM lies a novel approach: the use of read/write primitives. These primitives are designed to serve as a bridge between the memory matrix and the neural network itself.  Through rigorous evaluation across a diverse array of algorithmic tasks, we reveal that NAM stands shoulder to shoulder with the best in terms of efficiency and computational prowess.  To further illuminate its potential, we introduce two groundbreaking variants: Long Short-term Attention Memory (LSAM) and NAM-TM. LSAM is a generic RNN architecture designed to replace the long-term cell state of the recurrent neural network (RNN) with an attention mechanism. The NAM Turing Machine, on the other hand, is a"}
{"paper_id": 509, "abstract": "In the ever-evolving realm of machine learning, the quest for precision in data suppression stands as a formidable challenge. Traditionally, we find ourselves faced with the daunting task of curbing the sensitive attributes that stand in the way of downstream analytic applications. Yet, as we delve deeper into the intricate tapestry of multi-attribute datasets, we uncover a pivotal truth: the suppression of these attributes often leads to the loss of the data's potential for downstream applications.  In this paper, we unveil Multi-attribute Selective Suppression (MaSS), a groundbreaking framework designed to harness the power of precise suppression of arbitrary data attributes. At the heart of MaSS lies the ability to select an arbitrary set of attributes, selectively suppress them, while leaving the rest of the attributes intact for downstream analysis.  Through rigorous experimentation across a diverse array of datasets, including image, audio, and video, we demonstrate MaSS\u2019s prowess in achieving both attribute-specific and feature-preservation capabilities.  Our findings reveal that MaSS not only meets its objective but also surpasses it, surpassing the performance of traditional suppression techniques across diverse datasets."}
{"paper_id": 510, "abstract": "In the realm of weakly-supervised object localization (WSOL), where the quest for accuracy often feels like a struggle, the Class Activation Mapping (CAM) method emerges as a beacon of hope. This method harnesses the power of a Convolutional Neural Network (CNN) to navigate the complexities of object localization. Yet, it is not without its flaws: some heatmap-based XAI methods, such as GradCAM and Guided Backpropagation (GBP), have struggled to adapt to the demands of WSOL.   In this paper, we embark on a quest to assess the capabilities of existing CAM methods, uncovering their limitations and challenges.  To navigate these obstacles, we introduce a novel approach: the Neural Backed Decision Tree (NBDT). This innovative approach not only enhances the accuracy of our localization maps but also empowers us to enhance the localization capabilities of our existing methods.  Our findings reveal a remarkable truth: with the proper application of NBDT, heatmaps obtained from the inner layers of existing XAI models can surpass the original CAM without the need for any additional training. The results are striking: our method not only surpasses but also surpasses the performance of the baseline CAM"}
